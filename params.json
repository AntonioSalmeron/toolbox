{"name":"AMIDST Toolbox 1.0","tagline":"Analysis of MassIve Data STreams using Probabilistic Graphical Models","body":"# Scope\r\n\r\nThis toolbox offers a collection of scalable and parallel algorithms for inference and learning of hybrid Bayesian networks from streaming data. For example, AMIDST provides parallel multi-core implementations for Bayesian parameter learning, using streaming variational Bayes and variational message passing. Additionally, AMIDST efficiently leverages existing functionalities and algorithms by interfacing to existing software tools such as R, Weka, HUGIN and MOA. AMIDST is an open source toolbox written in Java and is available under the Apache Software License.\r\n\r\nIn the next figure we show a taxonomy of relevant data mining tools dealing with PGMs and data streams. To the best of our knowledge, there is no other software for mining data streams based on PGMs, most of the existing softwares based on PGMs are only focused on mining stationary data sets. Hence, the main goal of AMIDST is to fill this gap and produce a significant contribution within the areas of PGMs and mining streaming data.\r\n\r\n<p align=\"center\">\r\n<img title=\"Taxonomy\" src=\"https://github.com/amidst/toolbox/blob/master/doc/Taxonomy.png?raw=true\" width=\"400\">\r\n</p>\r\n\r\n\r\n# Scalability\r\n\r\nScalability is a main concern for the AMIDST toolbox. As mentioned before, we exploit Java 8 functional programming style to provide parallel implementations of most of our algorithms. If more computation capacity is needed to process data streams, AMIDST users can also use more CPU cores. As an example, the following figure shows how the data processing capacity of our toolbox increases with the number of cores when learning a hybrid BN model with latent variables using the AMIDST's learning engine. More precisely we learn a PGM model with multinomial (blue nodes) and Gaussian (green nodes) variables, some of them are latent, non observable, variables (dashed nodes). As can be seen, using our variational learning engine AMIDST toolbox is able to process data in the order of gigabytes per hour depending on the number of available cores with large and complex PGMs with latent variables.\r\n\r\n<p align=\"center\">\r\n<img src=\"https://github.com/amidst/toolbox/blob/master/doc/Scalability.png?raw=true\" width=\"800\">\r\n</p>\r\n\r\n\r\n# Documentation<a name=\"documentation\"></a>\r\n\r\n1. [Toolbox Functionalities](#functionalities)\r\n   * [Data Streams](#datastreams)\r\n   * [Probabilistic Graphical Models](#pgms)\r\n   * [Inference Engine](#inference)\r\n   * [Learning Engine](#learning)\r\n   * [Concept Drift](#conceptdrift)\r\n   * [Links to MOA, Weka, Hugin and R](#librarylinks)\r\n2. [Toolbox Architecture](#architecture)\r\n   * [Description](#description)\r\n   * [Java 8 Integration: Lambdas, streams, and functional-sytle programming](#java8)\r\n   * [Installation](#installation)\r\n   * [Compiling & Running from the command line](#compilation)\r\n   * [Extending AMIDST with Github Fork & Pull scheme](#extension)\r\n3. [Code Examples](#examples)\r\n   * [Data Streams](#datastreamsexample)\r\n   * [Variables](#variablesexample)\r\n4. [Java Doc](http://amidst.github.io/toolbox/javadoc/index.html)\r\n\r\n\r\n## Toolbox Functionalities<a name=\"functionalities\"></a>\r\n\r\nThe AMIDST is an open source Java 8 toolbox that makes use of functional programming style to provide parallel processing on mutli-core CPUs \\citep{CIM2015}. AMIDST provides a collection of functionalities and algorithms for learning hybrid Bayesian networks from streaming data. In what follows, we describe the main functionalities that AMIDST toolbox supplies.\r\n\r\n###Data Streams<a name=\"datastreams\"></a> \r\nAMIDST provides parallel processing built-in functionalities for dealing with streaming data \\citep{CIM2015}. It is possible to make several passes over the data samples if the stream can be stored on disk, otherwise the samples are discarded after being processed. The data format supported by AMIDST is Weka's ARFF (Attribute-Relation File Format) \\citep{Hall2009}.\r\n\r\n###Probabilistic Graphical Models<a name=\"pgms\"></a>\r\nAMIDST currently includes efficient implementations for representing Bayesian networks. AMIDST supports both discrete and continuous variables, and besides Multionomial, Gaussian and conditional linear Gaussian distributions, it also supports other distributions such as Gamma, Poission, Dirichlet, etc. as far as the final BN can be represented as a \\textit{conjugate-exponential family model} \\citep{WinnBishop2005}.  Other kind of probabilistic graphical models, such as dynamic BNs, are expected to be included in this toolbox.\r\n\r\n###Inference Engine<a name=\"inference\"></a>\r\nAMIDST includes the implementation of the \\textit{variational message passing} \\citep{WinnBishop2005} algorithm, and the parallel implementation of the \\textit{importance sampling} \\citep{hammersley1964monte,CAEPIA2015} algorithm. It also supports exact inference by interfacing with Hugin's junction tree inference algorithm \\citep{Madsen2005Hugin}. \r\n\r\n###Learning Engine<a name=\"learning\"></a>  \r\nIn AMIDST, a fully Bayesian approach is pursued, which means that the parameter learning reduces to the task of inference. AMIDST provides a multi-core parallel implementation of the \\textit{streaming variational Bayes} algorithm \\citep{broderick2013streaming}, using \\textit{variational message passing} as underlying inference engine, which can deal with large models with latent variables. When the model does not contain latent variables, an efficient parallel implementation of \\textit{maximum likelihood estimation} \\citep{mlestimation} can be also used by exploiting an efficient vector-based representation of BNs as \\textit{exponential family models} \\citep{WinnBishop2005}. For structural learning, AMIDST currently supports standard PC and parallel TAN algorithms by interfacing with HUGIN \\citep{Madsen2005Hugin,Madsen2014}.\r\n\r\n###Concept drift<a name=\"conceptdrift\"></a> \r\nAMIDST also offers some support for dealing with concept drift while learning BNs from data streams. Firstly, we provide an extension of the \\textit{streaming variational Bayes} algorithm \\citep{broderick2013streaming} which exponentially down-weights the influence of \\textit{old} data samples with the use of a fading factor (TODO). So, models learnt with this approach will be \\textit{focused} in most recent data. In addition, AMIDST provides a probabilistic concept drift detector based on the use of latent variables \\citep{IDA2015}.\r\n\r\n###Links to MOA, Weka, Hugin and R<a name=\"librarylinks\"></a> \r\nAMIDST leverages existing functionalities and algorithms by interfacing to existing software tools such as R, Weka, HUGIN and MOA (Massive Online Analysis) \\citep{BifetHolmesKirkbyPfahringer10}. This allows to efficiently well established systems and also broaden the AMIDST user-base. \r\n\r\n* **HuginLink** consists of a set of functionalities implemented to link the AMIDST toolbox with the HUGIN software \\citep{Madsen2005Hugin}. This connection extends AMIDST by providing the main functionalities integrated in Hugin software, such as exact inference algorithms and scalable structural learning algorithms \\citep{Madsen2014}. \r\n\r\n* **MoaLink** ensures an easy use of AMDIST functionalities within MOA \\citep{BifetHolmesKirkbyPfahringer10}.  The main idea is that any model deployed in AMIDST can be integrated and evaluated using MOA's graphical user interface. As a proof of concept, \\textit{MoaLink} already provides a classification, a regression and a clustering method based on BN models with latent variables. These models are learnt in a streaming fashion using AMIDST learning engine. \r\n\r\n* **RLink** ....\r\n\r\n[[Back to Top]](#documentation)\r\n\r\n## Toolbox Code Architecture<a name=\"architecture\"></a>\r\n### Description<a name=\"description\"></a>\r\nAMIDST toolbox is an open source project under [Apache Software License 2.0](http://www.apache.org/licenses/LICENSE-2.0). It is written in Java and is based on [Apache Maven](https://en.wikipedia.org/wiki/Apache_Maven) for building and structuring the project. This toolbox is structured as [multi-module Maven project](http://books.sonatype.com/mvnex-book/reference/multimodule.html). Roughly speaking, a **Maven module** is an independent piece of software with explicit dependencies to other modules in the project and to other external libraries. Each module is placed in independent folders and contains an xml file describing its dependencies. In this current version, the toolbox is composed by the following four modules:\r\n\r\n* **Core module** contains all the main functionalities of the toolbox. It is placed in the *core* folder. Go to the [Java Doc](http://amidst.github.io/toolbox/javadoc/index.html) for details about the different Java classes. \r\n\r\n* **Examples module** contains basic code examples showing how to use the main functionalities of the toolbox. It is placed in the *examples* folder under the root project folder.\r\n\r\n* **MoaLink module** contains the code needed to use the AMIDST functionality within MOA. It is placed in the *moalink* folder  under the root project folder.\r\n\r\n* **HuginLink module** contains the code needed to use [Hugin software](www.hugin.com) within AMIDST. It is placed in the *huginlink* folder under the root project folder. \r\n\r\n[[Back to Top]](#documentation)\r\n\r\n### Java 8 Integration: Lambdas, streams, and functional-sytle programming<a name=\"java8\"></a>\r\n\r\nThis toolbox has been specifically designed for using the functional-style features provided by the Java 8 release. This design leverages these new features for developing easy-to-code parallel algorithms on mutli-core CPUs. As commented above, the main scalability properties of this toolbox rely on this functional-style approach introduced in Java 8. Our aim is that future developers can also exploit this specific design of the toolbox for easily developing new methods for dealing with massive data streams using PGMs.  \r\n\r\nOur paper [Probabilistic Graphical Models on Multi-Core CPUs using Java 8]() provides a deep discussion over the different design issues we had to face and how they were solved using Java 8 functional-style features. \r\n\r\n[[Back to Top]](#documentation)\r\n\r\n### Installation<a name=\"installation\"></a>\r\n\r\nThe first step is to install [Java 8](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html).  We strongly recommend [IntelliJ](http://www.jetbrains.com/idea/download/) as IDE tool because it has direct support of Maven and Github. \r\n\r\nNow, we detail two different installation settings based on Maven and IntelliJ. The first installation settings is for those who just want to use the AMIDST toolbox and do not plan to make contributions/extensions to this open software project. The second settings details how to proceed to be a contributor of this project. \r\n\r\n* **Using AMIDST** simply requires to create a new **Maven Project** using IntelliJ where your code will be placed. Then edit the file \"pom.xml\" and add the following lines referring to the link the AMIDST jar library inside the dependencies plugin (follow this [link](http://books.sonatype.com/mvnex-book/reference/customizing-sect-add-depend.html) for further details) and then you are ready to rock. \r\n\r\n        <dependency>\r\n            <groupId>eu.amidst.toolbox</groupId>\r\n            <artifactId>AMIDST</artifactId>\r\n            <version>1.0</version>\r\n        </dependency>\r\n \r\n* **Contributing to AMDIST** is based on the [Fork & Pull](https://help.github.com/articles/using-pull-requests/) collaboration model. Read this [guide](https://guides.github.com/activities/forking/) for full details about how to fork a project and make a pull request. Once you have forked the project and make a local copy to you computer, just you can just open with Intellij the project by pointing at the pom file.Further details about how to contribute to this project are given this [section](#extension). \r\n\r\n[[Back to Top]](#documentation)\r\n\r\n### Compiling & Running from the command line<a name=\"compilation\"></a>\r\n\r\n1. Install Maven: http://maven.apache.org/download.cgi  (follow specific instructions for your OS).\r\n\r\n2. Modify the file maven_startup.sh (which you can find in the root project folder) and fix the path of your maven (Line 5) and java installation (Line 9).\r\n\r\n3. Create (or modify if already exists) a file \".profile\" or \".bash_profile\" in you home directory and add the following line,\r\nwhich points to file \"maven_startup.sh\"\r\n\r\n        source <project-folder>/maven_startup.sh\r\n\r\n Now after restarting the terminal, mvn should work.\r\n\r\n\r\n4. The script \"compile.sh\" (which you can find in the root project folder) just compiles the whole project.\r\n\r\n\r\n5. The script \"run.sh\" (which you can find in the root project folder) should be used to run some class. For example,\r\n\r\n        ./run.sh eu.amidst.core.examples.learning.ParallelMaximumLikelihoodExample\r\n\r\n[[Back to Top]](#documentation)\r\n\r\n### Extending AMIDST with Github Fork & Pull scheme<a name=\"extension\"></a>\r\n\r\nDevelopers are expected to contribute to this open software following the [Fork & Pull](https://help.github.com/articles/using-pull-requests/) collaboration model. Read this [guide](https://guides.github.com/activities/forking/) for full details about how to fork a project and make a pull request.\r\n\r\nSome of these collaboration approaches should be followed depending the kind of contribution you are aiming at:\r\n\r\n* **Basic Contributions** encompasses those contributions to the code that do not imply any major change or addition. For example, fixing a bug, adding methods to existing classes, adding new utility classes, etc. This contributions are made through a [pull request](https://help.github.com/articles/using-pull-requests/), which will be examined by the core group of developers of the project. \r\n\r\n* **Major Extensions** refers to those contributions which aims to be a new functionality of the toolbox. For example, a new inference/learning algorithm, new PGMs, etc. These extensions or new functionalities will be integrated as new Maven modules will be located in the folder *extensions* under the root project folder. Contributing with a new extension will be based on the following three steps: (i) create a new Maven module using IntelliJ (follow this [link](https://www.jetbrains.com/idea/help/creating-maven-module.html) for details); (ii) code your new algorithm inside this module; and (iii) make a [pull request](https://help.github.com/articles/using-pull-requests/) to add the new functionality to the project repository. \r\n \r\n[[Back to Top]](#documentation)\r\n\r\n## Code Examples<a name=\"examples\"></a>\r\n\r\n### Data Streams<a name=\"datastreamsexample\"></a>\r\n  \r\nIn this example we show how to use the main features of a *DataStream* object. More precisely,  we show six different ways of iterating over the data samples of a *DataStream* object.\r\n\r\n\r\n```java\r\n//We can open the data stream using the static class DataStreamLoader\r\nDataStream<DataInstance> data = DataStreamLoader.openFromFile(\"datasets/SmallDataSet.arff\");\r\n\r\n//Access to the attributes defining the data set\r\nSystem.out.println(\"Attributes defining the data set\");\r\nfor (Attribute attribute : data.getAttributes()) {\r\n    System.out.println(attribute.getName());\r\n}\r\nAttribute attA = data.getAttributes().getAttributeByName(\"A\");\r\n\r\n//1. Iterating over samples using a for loop\r\nSystem.out.println(\"1. Iterating over samples using a for loop\");\r\nfor (DataInstance dataInstance : data) {\r\n    System.out.println(\"The value of attribute A for the current data instance is: \" + dataInstance.getValue(attA));\r\n}\r\n\r\n\r\n//2. Iterating using streams. We need to restart the data again as a DataStream can only be used once.\r\nSystem.out.println(\"2. Iterating using streams.\");\r\ndata.restart();\r\ndata.stream().forEach(dataInstance ->\r\n                System.out.println(\"The value of attribute A for the current data instance is: \" + dataInstance.getValue(attA))\r\n);\r\n\r\n\r\n//3. Iterating using parallel streams.\r\nSystem.out.println(\"3. Iterating using parallel streams.\");\r\ndata.restart();\r\ndata.parallelStream(10).forEach(dataInstance ->\r\n                System.out.println(\"The value of attribute A for the current data instance is: \" + dataInstance.getValue(attA))\r\n);\r\n\r\n//4. Iterating over a stream of data batches.\r\nSystem.out.println(\"4. Iterating over a stream of data batches.\");\r\ndata.restart();\r\ndata.streamOfBatches(10).forEach(batch -> {\r\n    for (DataInstance dataInstance : batch)\r\n        System.out.println(\"The value of attribute A for the current data instance is: \" + dataInstance.getValue(attA));\r\n});\r\n\r\n//5. Iterating over a parallel stream of data batches.\r\nSystem.out.println(\"5. Iterating over a parallel stream of data batches.\");\r\ndata.restart();\r\ndata.parallelStreamOfBatches(10).forEach(batch -> {\r\n    for (DataInstance dataInstance : batch)\r\n        System.out.println(\"The value of attribute A for the current data instance is: \" + dataInstance.getValue(attA));\r\n});\r\n\r\n\r\n//6. Iterating over data batches using a for loop\r\nSystem.out.println(\"6. Iterating over data batches using a for loop.\");\r\nfor (DataOnMemory<DataInstance> batch : data.iterableOverBatches(10)) {\r\n    for (DataInstance dataInstance : batch)\r\n        System.out.println(\"The value of attribute A for the current data instance is: \" + dataInstance.getValue(attA));\r\n}\r\n```\r\n\r\n[[Back to Top]](#documentation)\r\n### Variables<a name=\"variablesexample\"></a>\r\n\r\n\r\n[[Back to Top]](#documentation)","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}